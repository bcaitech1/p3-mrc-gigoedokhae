{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/outputs/models/no1_concat_korquad1_datasets_10epochs\n",
      "model is from bert-base-multilingual-cased\n",
      "data is from /opt/ml/input/data/train_dataset\n",
      "model uses device: cuda:0\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
      "        num_rows: 3952\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
      "        num_rows: 240\n",
      "    })\n",
      "})\n",
      "WARNING:datasets.builder:Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 29.42ba/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 125.84ba/s]\n",
      "100%|███████████████████████████████████████████| 61/61 [00:01<00:00, 39.34ba/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:00<00:00, 43.15ba/s]\n",
      "100%|███████████████████████████████████████████| 71/71 [00:40<00:00,  1.77ba/s]\n",
      "{'loss': 3.7324, 'learning_rate': 3.399048266485384e-06, 'epoch': 0.34}         \n",
      "{'loss': 1.0964, 'learning_rate': 6.798096532970768e-06, 'epoch': 0.68}         \n",
      "{'loss': 0.7834, 'learning_rate': 9.999881607641675e-06, 'epoch': 1.02}         \n",
      "{'loss': 0.6415, 'learning_rate': 9.960656738602143e-06, 'epoch': 1.36}         \n",
      " 14%|████▊                             | 2075/14710 [1:30:52<9:13:25,  2.63s/it]"
     ]
    }
   ],
   "source": [
    "from utils import increment_path\n",
    "\n",
    "exp_name = \"concat_korquad1_datasets_10epochs\"\n",
    "model_output_dir = increment_path(\"/opt/ml/outputs/models\", \"/no\", exp_name)\n",
    "print(model_output_dir)\n",
    "!python train.py --do_train\\\n",
    "    --run_name None\\\n",
    "    --output_dir $model_output_dir\\\n",
    "    --overwrite_output_dir False\\\n",
    "    --seed 42\\\n",
    "    --fp16 True --fp16_opt_level \"O1\"\\\n",
    "    --dataloader_pin_memory True\\\n",
    "    --dataloader_drop_last False\\\n",
    "    \\\n",
    "    --num_train_epochs 10.0\\\n",
    "    --per_device_train_batch_size 16 --gradient_accumulation_steps 4\\\n",
    "    --evaluation_strategy \"no\"\\\n",
    "    --save_strategy \"epoch\"\\\n",
    "    --save_total_limit 3\\\n",
    "    \\\n",
    "    --learning_rate 1e-5 --lr_scheduler_type \"cosine\"\\\n",
    "    --warmup_ratio 0.1\\\n",
    "    --weight_decay 0.001 --adam_beta1 0.9 --adam_beta2 0.999 --adam_epsilon 1e-8\\\n",
    "    --adafactor False\\\n",
    "    --max_grad_norm 1.0\\\n",
    "    \\\n",
    "    --group_by_length False\\\n",
    "    --label_smoothing_factor 0.5\n",
    "    \n",
    "print(\"end training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is from /opt/ml/input/data/test_dataset\n",
      "model is from /opt/ml/outputs/models/exp1_BM25_concat_datasets/checkpoint-1570\n",
      "model uses device: cuda:0\n",
      "Dataset({\n",
      "    features: ['id', 'question'],\n",
      "    num_rows: 600\n",
      "})\n",
      "Lengths of unique contexts : 56607\n",
      "Passage Embedding Loaded.\n",
      "[Relevant documents exhaustive search.] done in 6.028 s\n",
      "Making DataFrame dataset:: 600it [00:00, 18702.17it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:27<00:00,  4.61s/ba]\n",
      "Init Trainer...\n",
      "100%|███████████████████████████████████████| 1283/1283 [02:17<00:00,  9.27it/s]INFO:utils_qa:Post-processing 6000 example predictions split into 10262 features.\n",
      "100%|██████████████████████████████████████| 6000/6000 [00:37<00:00, 160.25it/s]\n",
      "INFO:utils_qa:Saving predictions to /opt/ml/outputs/preds/no2_mecab_with_khaiii/predictions.json.\n",
      "INFO:utils_qa:Saving nbest_preds to /opt/ml/outputs/preds/no2_mecab_with_khaiii/nbest_predictions.json.\n",
      "No metric can be presented because there is no correct answer given. Job done!\n",
      "100%|███████████████████████████████████████| 1283/1283 [03:08<00:00,  6.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils import increment_path\n",
    "\n",
    "exp_name = \"mecab_with_khaiii\"\n",
    "test_output_dir = increment_path(\"/opt/ml/outputs/preds\", \"/no\", exp_name)\n",
    "\n",
    "dataset_path = \"/opt/ml/input/data/test_dataset\"\n",
    "model_path = \"/opt/ml/outputs/models/exp1_BM25_concat_datasets/checkpoint-1570\"\n",
    "!python inference.py\\\n",
    "    --do_predict\\\n",
    "    --output_dir $test_output_dir\\\n",
    "    --dataset_name $dataset_path\\\n",
    "    --model_name_or_path $model_path\\\n",
    "    --topk 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_output_dir = increment_path(\"./outputs/train_dataset\", \"/exp\", exp_name)\n",
    "!python train.py\\\n",
    "    --do_eval\\\n",
    "    --output_dir $eval_output_dir\\\n",
    "    --model_name_or_path $model_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 348, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 34, in main\n",
      "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/hf_argparser.py\", line 196, in parse_args_into_dataclasses\n",
      "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
      "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--', 'eval_accumulation_steps', '1', '--evaluation_strategy', 'epoch', '--logging_strategy', 'steps', '--logging_steps', '500', '--save_strategy', 'epoch', '--save_steps', '500', '--save_total_limit', '3', '--load_best_model_at_end', 'False', '--learning_rate', '5e-5', '--lr_scheduler_type', 'constant_with_warmup', '--warmup_ratio', '0.0', '--warmup_steps', '0', '--weight_decay', '0', '--adam_beta1', '0.9', '--adam_beta2', '0.999', '--adam_epsilon', '1e-8', '--adafactor', 'False', '--max_grad_norm', '1.0', '--group_by_length', 'False', '--label_smoothing_factor', '0.0', '--do_train']\n"
     ]
    }
   ],
   "source": [
    "!python train.py --do_train\\\n",
    "    --run_name None\\\n",
    "    --output_dir ./models/train_dataset --overwrite_output_dir False\\\n",
    "    --seed 42\\\n",
    "    --fp16 True --fp16_opt_level \"O1\"\\\n",
    "    --dataloader_num_workers 4\\\n",
    "    --dataloader_pin_memory True\\\n",
    "    --dataloader_drop_last False\\\n",
    "    \\\n",
    "    --num_train_epochs 10.0\\\n",
    "    --per_device_train_batch_size 16 --gradient_accumulation_steps 1\\\n",
    "    --per_device_eval_batch_size 16 -- eval_accumulation_steps 1\\\n",
    "    --evaluation_strategy \"epoch\"\\\n",
    "    --logging_strategy \"steps\" --logging_steps 500\\\n",
    "    --save_strategy \"epoch\"\\\n",
    "    --save_steps 500 --save_total_limit 3\\\n",
    "    --load_best_model_at_end False\\\n",
    "    \\\n",
    "    --learning_rate 5e-5 --lr_scheduler_type \"cosine\"\\\n",
    "    --warmup_ratio 0.0 --warmup_steps 0\\\n",
    "    --weight_decay 0.01 --adam_beta1 0.9 --adam_beta2 0.999 --adam_epsilon 1e-8\\\n",
    "    --adafactor False\\\n",
    "    --max_grad_norm 1.0\\\n",
    "    \\\n",
    "    --group_by_length False\\\n",
    "    --label_smoothing_factor 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EvaluationStrategy, IntervalStrategy(ExplicitEnum):\n",
    "    NO = \"no\"\n",
    "    STEPS = \"steps\"\n",
    "    EPOCH = \"epoch\"\n",
    "\n",
    "# class SchedulerType(ExplicitEnum):\n",
    "    LINEAR = \"linear\"\n",
    "    COSINE = \"cosine\"\n",
    "    COSINE_WITH_RESTARTS = \"cosine_with_restarts\"\n",
    "    POLYNOMIAL = \"polynomial\"\n",
    "    CONSTANT = \"constant\"\n",
    "    CONSTANT_WITH_WARMUP = \"constant_with_warmup\"\n",
    "\n",
    "# fp16_opt_level: https://nvidia.github.io/apex/amp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
