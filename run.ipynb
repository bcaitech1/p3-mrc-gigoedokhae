{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/outputs/models/no1_xlm_roberta\n",
      "data is from /opt/ml/input/data/train_dataset\n",
      "model is from hanmaroo/xlm_roberta_large_korquad_v1\n",
      "model uses device: cuda:0\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
      "        num_rows: 3952\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
      "        num_rows: 240\n",
      "    })\n",
      "})\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00, 28.44ba/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 113.30ba/s]\n",
      "train dataset:\n",
      " Dataset({\n",
      "    features: ['answers', 'context', 'id', 'question', 'title'],\n",
      "    num_rows: 4192\n",
      "})\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:04<00:00,  1.22ba/s]\n",
      "Init Trainer...\n",
      "  0%|                                                  | 0/1176 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "{'loss': 0.6997, 'learning_rate': 3.5569194125382122e-06, 'epoch': 1.7}         \n",
      " 75%|████████████████████████████▌         | 882/1176 [1:05:16<21:14,  4.33s/it]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 364, in save\n",
      "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 483, in _save\n",
      "    zip_file.write_record(name, buf_value, len(buf_value))\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 181, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 141, in main\n",
      "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\", line 1178, in train\n",
      "    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\", line 1269, in _maybe_log_save_evaluate\n",
      "    self._save_checkpoint(model, trial, metrics=metrics)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\", line 1319, in _save_checkpoint\n",
      "    torch.save(self.optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 365, in save\n",
      "    return\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/serialization.py\", line 258, in __exit__\n",
      "    self.file_like.write_end_of_file()\n",
      "RuntimeError: [enforce fail at inline_container.cc:262] . unexpected pos 1175945600 vs 1175945488\n",
      "terminate called after throwing an instance of 'c10::Error'\n",
      "  what():  [enforce fail at inline_container.cc:262] . unexpected pos 1175945600 vs 1175945488\n",
      "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7f8fc8c036c7 in /opt/conda/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0x1feb390 (0x7f8ffd067390 in /opt/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: <unknown function> + 0x1fe75c3 (0x7f8ffd0635c3 in /opt/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0x17b (0x7f8ffd06856b in /opt/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x7f8ffd069101 in /opt/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x7f8ffd0698f5 in /opt/conda/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #6: <unknown function> + 0x5a5463 (0x7f90024eb463 in /opt/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #7: <unknown function> + 0x26519e (0x7f90021ab19e in /opt/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #8: <unknown function> + 0x26676e (0x7f90021ac76e in /opt/conda/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "<omitting python frames>\n",
      "frame #22: __libc_start_main + 0xe7 (0x7f901d97fbf7 in /lib/x86_64-linux-gnu/libc.so.6)\n",
      "\n",
      "Aborted (core dumped)\n",
      "Training End.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device: '/opt/ml/outputs/models/no1_xlm_roberta/zeof'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-fdf4e8bfb56d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0meof_dir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/zeof\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meof_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: '/opt/ml/outputs/models/no1_xlm_roberta/zeof'"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.soundjay.com/button/beep-07.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.soundjay.com/button/beep-07.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.soundjay.com/button/beep-07.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import increment_path\n",
    "\n",
    "import os\n",
    "from IPython.lib.display import Audio\n",
    "import numpy as np\n",
    "\n",
    "# ********** CHANGE HERE (1/2): Name for the path of reader model to be saved **********\n",
    "exp_name = \"xlm_roberta\"\n",
    "# **************************************************************************************\n",
    "model_output_path = increment_path(\"/opt/ml/outputs/models\", \"/no\", exp_name)\n",
    "print(model_output_path)\n",
    "\n",
    "# ********** CHANGE HERE (2/2): Path of state of reader model if needed, else \"no\" (default). **********\n",
    "#model_state_path = \"/opt/ml/outputs/models/no1_state_1epoch_with_korquad/bert-base-multilingual-cased_state_dict.pth\"\n",
    "# ******************************************************************************************************\n",
    "# seed == 42 (default)\n",
    "# ********** CHANGE with parser: train_korquad / save_state_only / num_train_epochs\n",
    "!python train.py\\\n",
    "    --train_korquad False\\\n",
    "    --save_state_only False\\\n",
    "    --model_state_path $model_state_path\\\n",
    "    \\\n",
    "    --output_dir $model_output_path\\\n",
    "    --fp16 True --fp16_opt_level \"O1\"\\\n",
    "    --dataloader_pin_memory True\\\n",
    "    --dataloader_drop_last False\\\n",
    "    \\\n",
    "    --num_train_epochs 4.0\\\n",
    "    --per_device_train_batch_size 8 --gradient_accumulation_steps 4\\\n",
    "    --save_strategy \"epoch\"\\\n",
    "    --save_total_limit 3\\\n",
    "    \\\n",
    "    --learning_rate 5e-6 --lr_scheduler_type \"cosine\"\\\n",
    "    --warmup_ratio 0.1\\\n",
    "    --weight_decay 0.001 --adam_beta1 0.9 --adam_beta2 0.999 --adam_epsilon 1e-8\\\n",
    "    --adafactor False\\\n",
    "    --max_grad_norm 1.0\\\n",
    "    \\\n",
    "    --group_by_length False\\\n",
    "    --label_smoothing_factor 0.5\n",
    "\n",
    "print(\"Training End.\")\n",
    "\n",
    "if os.path.isdir(model_output_path):\n",
    "    eof_dir_path = model_output_path + \"/zeof\"\n",
    "    os.mkdir(eof_dir_path)\n",
    "\n",
    "def beep():\n",
    "    framerate = 4410\n",
    "    play_time_seconds = 2\n",
    "\n",
    "    t = np.linspace(0, play_time_seconds, framerate*play_time_seconds)\n",
    "    audio_data = np.sin(2*np.pi*300*t) + np.sin(2*np.pi*240*t)\n",
    "    return Audio(audio_data, rate=framerate, autoplay=True)\n",
    "beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is from /opt/ml/input/data/test_dataset\n",
      "model is from /opt/ml/outputs/models/no1_xlm_roberta/checkpoint-882\n",
      "model uses device: cuda:0\n",
      "Dataset({\n",
      "    features: ['id', 'question'],\n",
      "    num_rows: 600\n",
      "})\n",
      "Lengths of unique contexts : 56607\n",
      "Passage Embedding Loaded.\n",
      "[Relevant documents exhaustive search.] done in 5.072 s\n",
      "Making DataFrame dataset:: 600it [00:00, 17230.49it/s]\n",
      "100%|███████████████████████████████████████████| 12/12 [00:50<00:00,  4.23s/ba]\n",
      "Init Trainer...\n",
      "100%|███████████████████████████████████████| 2426/2426 [13:19<00:00,  3.01it/s]INFO:utils_qa:Post-processing 12000 example predictions split into 19404 features.\n",
      "100%|████████████████████████████████████| 12000/12000 [01:06<00:00, 181.62it/s]\n",
      "INFO:utils_qa:Saving predictions to /opt/ml/outputs/preds/no1_xlm_roberta/predictions.json.\n",
      "INFO:utils_qa:Saving nbest_preds to /opt/ml/outputs/preds/no1_xlm_roberta/nbest_predictions.json.\n",
      "Job done! (No metric can be presented because there is no correct answer given.)\n",
      "100%|███████████████████████████████████████| 2426/2426 [14:47<00:00,  2.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.soundjay.com/button/beep-07.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.soundjay.com/button/beep-07.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.soundjay.com/button/beep-07.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import increment_path\n",
    "\n",
    "exp_name = \"xlm_roberta\"\n",
    "test_output_dir = increment_path(\"/opt/ml/outputs/preds\", \"/no\", exp_name)\n",
    "\n",
    "dataset_path = \"/opt/ml/input/data/test_dataset\"\n",
    "model_path = \"/opt/ml/outputs/models/no1_xlm_roberta/checkpoint-882\"\n",
    "!python inference.py\\\n",
    "    --output_dir $test_output_dir\\\n",
    "    --dataset_path $dataset_path\\\n",
    "    --model_path $model_path\\\n",
    "    --topk 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_output_dir = increment_path(\"./outputs/train_dataset\", \"/exp\", exp_name)\n",
    "!python train.py\\\n",
    "    --do_eval\\\n",
    "    --output_dir $eval_output_dir\\\n",
    "    --model_name_or_path $model_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 348, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 34, in main\n",
      "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/transformers/hf_argparser.py\", line 196, in parse_args_into_dataclasses\n",
      "    raise ValueError(f\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\")\n",
      "ValueError: Some specified arguments are not used by the HfArgumentParser: ['--', 'eval_accumulation_steps', '1', '--evaluation_strategy', 'epoch', '--logging_strategy', 'steps', '--logging_steps', '500', '--save_strategy', 'epoch', '--save_steps', '500', '--save_total_limit', '3', '--load_best_model_at_end', 'False', '--learning_rate', '5e-5', '--lr_scheduler_type', 'constant_with_warmup', '--warmup_ratio', '0.0', '--warmup_steps', '0', '--weight_decay', '0', '--adam_beta1', '0.9', '--adam_beta2', '0.999', '--adam_epsilon', '1e-8', '--adafactor', 'False', '--max_grad_norm', '1.0', '--group_by_length', 'False', '--label_smoothing_factor', '0.0', '--do_train']\n"
     ]
    }
   ],
   "source": [
    "!python train.py --do_train\\\n",
    "    --run_name None\\\n",
    "    --output_dir ./models/train_dataset --overwrite_output_dir False\\\n",
    "    --seed 42\\\n",
    "    --fp16 True --fp16_opt_level \"O1\"\\\n",
    "    --dataloader_num_workers 4\\\n",
    "    --dataloader_pin_memory True\\\n",
    "    --dataloader_drop_last False\\\n",
    "    \\\n",
    "    --num_train_epochs 10.0\\\n",
    "    --per_device_train_batch_size 16 --gradient_accumulation_steps 1\\\n",
    "    --per_device_eval_batch_size 16 -- eval_accumulation_steps 1\\\n",
    "    --evaluation_strategy \"epoch\"\\\n",
    "    --logging_strategy \"steps\" --logging_steps 500\\\n",
    "    --save_strategy \"epoch\"\\\n",
    "    --save_steps 500 --save_total_limit 3\\\n",
    "    --load_best_model_at_end False\\\n",
    "    \\\n",
    "    --learning_rate 5e-5 --lr_scheduler_type \"cosine\"\\\n",
    "    --warmup_ratio 0.0 --warmup_steps 0\\\n",
    "    --weight_decay 0.01 --adam_beta1 0.9 --adam_beta2 0.999 --adam_epsilon 1e-8\\\n",
    "    --adafactor False\\\n",
    "    --max_grad_norm 1.0\\\n",
    "    \\\n",
    "    --group_by_length False\\\n",
    "    --label_smoothing_factor 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EvaluationStrategy, IntervalStrategy(ExplicitEnum):\n",
    "    NO = \"no\"\n",
    "    STEPS = \"steps\"\n",
    "    EPOCH = \"epoch\"\n",
    "\n",
    "# class SchedulerType(ExplicitEnum):\n",
    "    LINEAR = \"linear\"\n",
    "    COSINE = \"cosine\"\n",
    "    COSINE_WITH_RESTARTS = \"cosine_with_restarts\"\n",
    "    POLYNOMIAL = \"polynomial\"\n",
    "    CONSTANT = \"constant\"\n",
    "    CONSTANT_WITH_WARMUP = \"constant_with_warmup\"\n",
    "\n",
    "# fp16_opt_level: https://nvidia.github.io/apex/amp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
