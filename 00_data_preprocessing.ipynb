{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'context', 'id', 'question', 'title'],\n",
       "    num_rows: 60407\n",
       "})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pyarrow as pa\n",
    "\n",
    "datasets = load_dataset(\"squad_kor_v1\")\n",
    "#datasets[\"train\"][\"question\"]\n",
    "#datasets\n",
    "\n",
    "org_datasets = []\n",
    "org_datasets.append(datasets[\"train\"])\n",
    "org_datasets.append(datasets[\"validation\"])\n",
    "\n",
    "new_pydict_list = []\n",
    "for org_dataset in org_datasets:\n",
    "    new_pydict = org_dataset.to_dict()\n",
    "    #context_list = [func(data) for data in new_pydict[\"context\"]]\n",
    "    #new_pydict[\"context\"] = context_list\n",
    "    new_pydict_list.append(new_pydict)\n",
    "\n",
    "new_table_list = []\n",
    "for i in range(2):\n",
    "    new_table_list.append(pa.Table.from_pydict(new_pydict_list[i]))\n",
    "\n",
    "train_dataset = Dataset(new_table_list[0])\n",
    "valid_dataset = Dataset(new_table_list[1])\n",
    "#datasets = DatasetDict({\"train\": train_dataset, \"validation\": valid_dataset})\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'context', 'id', 'question', 'title'],\n",
       "    num_rows: 60407\n",
       "})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasets = load_dataset(\"squad_kor_v1\")\n",
    "\n",
    "df = pd.DataFrame(datasets[\"train\"])\n",
    "#Dataset.from_pandas(df)\n",
    "Dataset(pa.Table.from_pandas(df))\n",
    "#table = pa.Table.from_pandas(df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'context', 'id', 'question', 'title'],\n",
       "    num_rows: 3952\n",
       "})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk, Features, Sequence, Value\n",
    "datasets = load_from_disk(\"/opt/ml/input/data/train_dataset\")\n",
    "\n",
    "train_dataset = datasets[\"train\"]\n",
    "eval_dataset = datasets[\"validation\"]\n",
    "\n",
    "def preprocess_features_of_Dataset(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "\n",
    "    features = Features({\n",
    "        \"answers\": Sequence(feature={\n",
    "            \"text\": Value(dtype=\"string\", id=None),\n",
    "            \"answer_start\": Value(dtype=\"int32\", id=None)\n",
    "        }, length=-1, id=None),\n",
    "        \"context\": Value(dtype=\"string\", id=None),\n",
    "        \"id\": Value(dtype=\"string\", id=None),\n",
    "        \"question\": Value(dtype=\"string\", id=None),\n",
    "        \"title\": Value(dtype=\"string\", id=None),\n",
    "    })\n",
    "\n",
    "    return Dataset.from_pandas(df, features=features)\n",
    "\n",
    "preprocess_features_of_Dataset(train_dataset)\n",
    "\n",
    "#train_dataset.map(features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'context',\n",
       " 'question',\n",
       " 'id',\n",
       " 'answers',\n",
       " 'document_id',\n",
       " '__index_level_0__']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wiki docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def func(s):\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\n\\n\", \" \")\n",
    "    s = s.replace(\"\\n\", \" \")\n",
    "    s = s.replace(\"#\", \"\")\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    return s\n",
    "\n",
    "data_path = \"/opt/ml/input/data/wikipedia_documents.json\"\n",
    "with open(data_path) as f:\n",
    "    dataset = json.load(f)\n",
    "print(len(dataset.unique()))\n",
    "\n",
    "cnt = 0\n",
    "for k, v in dataset.items():\n",
    "    dataset[k][\"text\"] = func(v[\"text\"])\n",
    "\n",
    "data_path = \"/opt/ml/input/data/new_wikipedia_documents.json\"\n",
    "with open(data_path, \"w\") as f:\n",
    "    json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.\\n\\n이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.\\n\\n# 첫 번째 부분은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다.\\n# 두 번째 부분은 일부 지역의 주권을 사실상 (데 팍토) 행사하고 있지만, 아직 국제적인 승인을 널리 받지 않았다고 여기는 11개 나라를 나열하고 있다.\\n\\n두 목록은 모두 가나다 순이다.\\n\\n일부 국가의 경우 국가로서의 자격에 논쟁의 여부가 있으며, 이 때문에 이러한 목록을 엮는 것은 매우 어렵고 논란이 생길 수 있는 과정이다. 이 목록을 구성하고 있는 국가를 선정하는 기준에 대한 정보는 \"포함 기준\" 단락을 통해 설명하였다. 나라에 대한 일반적인 정보는 \"국가\" 문서에서 설명하고 있다.',\n",
       " 'corpus_source': '위키피디아',\n",
       " 'url': 'TODO',\n",
       " 'domain': None,\n",
       " 'title': '나라 목록',\n",
       " 'author': None,\n",
       " 'html': None,\n",
       " 'document_id': 0}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets\n",
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from retrieval import get_dataset_with_retrieval\n",
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments\n",
    "\n",
    "data_path = \"/opt/ml/input/data/train_dataset\"\n",
    "dataset = load_from_disk(data_path)\n",
    "#dataset[\"validation\"][\"answers\"]\n",
    "#get_dataset_with_retrieval(dataset, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "data_path2 = \"/opt/ml/input/data/test_dataset\"\n",
    "dataset = load_from_disk(data_path2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "논문으로 플라톤주의의 허점을 언급한 사람은?\n"
     ]
    }
   ],
   "source": [
    "for data in dataset[\"validation\"]:\n",
    "    if data[\"id\"] == \"mrc-0-003223\":\n",
    "        print(data[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 측에서 주장된 포로교환 방법 중 선택된 것은?\n",
      "한국에서 음식을 올려놓을때 쓰이는 세간의 이름은 무엇인가요?\n",
      "미자르는 무엇의 일부인가?\n",
      "해안포를 정착해 해안을 방어하기 위해 건설한 것은?\n",
      "찰스 2세가 국내로 돌아오기 전에 있던 국가는?\n",
      "나카무라 번이 메이지 정부에 굴복하게 된 결투의 이름은 무엇인가요?\n",
      "예수의 테오토코스에 대해 부정적으로 인식했던 인물은?\n",
      "윤치호가 사촌동생을 통해 만나려고 했던 인물은?\n",
      "홉베마의 스승은 누구인가요?\n",
      "슈타우펜베르크는 들 것에 실려나온 사람이 무엇을 덮고 있는 것을 보고 히틀러의 죽음을 단정했나?\n",
      "아즈마의 초기 명칭은?\n",
      "경찰은 어떤 기관의 GPS를 이용하여 오원춘을 체포할 수 있었나요?\n",
      "자미토프가 개혁을 강행하기 위해 설립한 사병 집단은?\n",
      "드레이어 감독이 잔 다르크에 비유한 사람은?\n",
      "교전 당사자에 대한 전쟁 범죄 심판시 판단 기준이 되는 법은?\n",
      "단공류가 일반 포유류와 다르다는 것을 알 수 있는 신체 부위는?\n",
      "카쿠와 로브 루치의 현재 신분은?\n",
      "출혈성 천연두 초기와 말기 환자 모두에게 증가하는 물질은?\n",
      "사라스테의 후임은 누구인가?\n",
      "미자가 일을 때려친 것은 누구 때문인가?\n",
      "사이트에 올라오는 콘텐츠를 검열하는 주체는 누구인가?\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "data_path = \"/opt/ml/input/data/dummy_dataset\"\n",
    "dataset1 = load_from_disk(data_path)\n",
    "\n",
    "data_path = \"/opt/ml/input/data/train_dataset\"\n",
    "dataset2 = load_from_disk(data_path)\n",
    "\n",
    "cnt = 0\n",
    "for question in dataset1[\"train\"][\"question\"]:\n",
    "    if question not in dataset2[\"train\"][\"question\"]\\\n",
    "    and question not in dataset2[\"validation\"][\"question\"]:\n",
    "        print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "     num_rows: 3952\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "     num_rows: 240\n",
       " })]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "data_path = \"/opt/ml/input/data/train_dataset\"\n",
    "datasets = load_from_disk(data_path)\n",
    "org_datasets = []\n",
    "org_datasets.append(datasets[\"train\"])\n",
    "org_datasets.append(datasets[\"validation\"])\n",
    "\n",
    "org_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /opt/ml/input/data/train_dataset/train/cache-5864ec783ab77348.arrow\n",
      "Loading cached processed dataset at /opt/ml/input/data/train_dataset/validation/cache-ec5c6075463087d0.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "    num_rows: 4192\n",
       "})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "full_ds = concatenate_datasets([\n",
    "    datasets[\"train\"].flatten_indices(),\n",
    "    datasets[\"validation\"].flatten_indices(),\n",
    "])\n",
    "full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "많은 갈등을 불러온 툴민의 책은? ≪인간의 이해: 개념의 집단적 사용 및 진화 (1972)≫\n",
      "에릭 레이먼드의 자유 소프트웨어 철학을 대변하는 글은? 〈성당과 시장〉(The Cathedral and the Bazaar)\n",
      "알바니아계 이탈리아 교회가 소속된 교구는? 룬그로 (이탈리아 대륙에 거주하는 아르버레셔인을 위한) 교구\n",
      "판스워스 교수가 이전 배달원에 대해 한 대사는? \"오 그 불쌍한 사람들... 그러나 그건 별로 중요하지 않아요! 중요한건 난 새로운 배달원이 필요했다는 거지!\"\n",
      "강중인이 경제사범을 비판하며 국민의 일대수치라 표현한 글은? 최근의 반도의 경제사범 ­국민의 신경제 윤리의 파악을 위하여­\n",
      "도스토옙스키의 시력이 망가졌을 때 그는 어떤 방식으로 작품을 완성할 수 있었나? 도스토옙스키가 침대 누워 구술한 것을 아내 안나가 속기 하여\n",
      "영어로 Presocratics란 뜻을 가진 낱말의 기원은? 독일의 고전 문헌학자 헤르만 딜스가 이들 철학자의 단편들을 한데 모아 엮은 책의 제목\n",
      "두 개의 지역으로 줄어든 후에 킬리키아의 명칭은 무엇으로 변경되었나? 시리아킬리키아 포에니케 (Syria-Cilicia Phoenice)\n",
      "윤치호가 일부 독립운동 지도자들로부터 비난 받았던 일기의 내용은? “나는 국경일에 일장기를 게양하는 것을 반대하지 않는다. 왜냐하면 우리가 일본의 통치하에 있는 한 우리는 그 통치의 명령에 복종해야 하기 때문이다.”\n",
      "윤치호가 조지아주에서 재입학한 학교는? 에모리 대학(Oxford College of Emory University)\n",
      "우룡은 그림에서 어떤 모습으로 묘사되었는가? 머리가 크고, 가늘고 허약해 보이는 동체를 꼬아놓은 모습\n",
      "공공사업과 관련한 갈등이 유발되는 현장에서 사용되는 문구는 무엇인가? “나리타처럼 되지 말자(成田のようにならないようにしよう )”\n",
      "작품 《트로일러스와 크리세이드》가 일으키는 논란을 해결하기 어렵다고 본 사람은? 프레드릭 S. 보아스 (Frederick S. Boas)\n",
      "고고학자들은 어떤 상황일 때 원어를 활용해 원문을 복원하려고 하는가? 고문서로 발견된 유물이 원어로는 존재하지 않고 번역된 언어로만 존재할 경우\n",
      "바빌론의 공중정원이 실존했는지 정확히 알 수 없는 이유는? 당대의 바빌로니아 기록들이 현재까지 별로 많이 남아있지 않기 때문\n",
      "샤 자한의 관이 타지마할 전체에서 유일하게 대칭 구조를 띠지 않는다고 추측되는 이유는? 샤 자한이 이 무덤을 지을 때 자신이 그녀의 옆에 묻힐 것을 예상하지 못하였기 때문\n",
      "노랫말의 번역이 대구 시구 번역보다 훨씬 제약이 많은 이유는? 형태에 있어 거의 혹은 전혀 자유가 없어 다양한 번역을 창조해내기가 불가능하고 시구 구조에서도 다른 여지를 찾기 어려운 탓이다.\n",
      "자캐오가 회개의 결단을 표현한 말은? \"소유의 절반을 가난한 자들에게 주겠으며, 만일 누구의 것을 부당하게 취한 일이 있으며 사 배나 보상할 것\"\n",
      "마르크수 주의를 주장하는 사람들이 자본국가를 어떻게 지칭하는가? “부르주아 독재(Dictatorship of the bourgeoisie)”\n",
      "삼성이 더이상 한겨레를 광고하지 않는 까닭은? 한겨레가 삼성에 대해 악의적인 보도로 일관하고 있다고 판단\n",
      "개인 사용자가 각자 사용할 데이터베이스를 디자인하는 것을 쉽게 해준 프로그램은? 매킨토시와 도스 상에서 ‘설정 가능한’ 플랫 파일 데이터베이스 응용 프로그램\n",
      "기후 변화 대응 체계 해소 취지에 선구할 수 있는 방안으로 대두되는 농업 장소는? 주거 및 상업시설 복합 건축물의 상업 지역 부분 옥상 등지\n",
      "유명 작곡가들의 교향곡이 9번에서 끝난 것을 표현하는 말은? 제9번이 마지막 교향곡이 된다는 운명적 신화 (9번 교향곡의 저주)\n",
      "고권삼이 친일인명사전 수록예정자 명단 중 해외 부문에 포함된 이유는 무엇 때문인가? 황도철학이라는 어용 학문을 연구해 다수의 논설을 발표한 일\n",
      "토머스는 어떤 사건으로 인해 1년간의 보호 관찰을 받았나? USS 사라토가 호에서 조지 로엡이 흑인 수병 해럴드 J. 맨스필드를 총으로 쏘아 살해한 사건\n"
     ]
    }
   ],
   "source": [
    "n = 200\n",
    "for data in org_datasets[0]:\n",
    "    answer = data[\"answers\"][\"text\"][0]\n",
    "    if len(answer) > 30:\n",
    "        print(data[\"question\"], answer)\n",
    "#org_datasets[0][\"context\"][0][235:237]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## context: remove \"\\\\n\\\\n\"\n",
    "- 성능 향상을 보기 위해 context에 대해 처리, 저장, 실험한 후,  \n",
    "  나중에 이를 불러와서 answer에 대해 처리합니다. \n",
    "- train_dataset에만 있는 데이터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def func(s):\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\\\n\\\\n\", \" \")\n",
    "    s = s.replace(\"\\\\n\", \" \")\n",
    "    s = s.replace(\"#\", \"\")\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    return s\n",
    "\n",
    "new_pydict_list = []\n",
    "for org_dataset in org_datasets:\n",
    "    new_pydict = org_dataset.to_dict()\n",
    "    context_list = [func(data) for data in new_pydict[\"context\"]]\n",
    "    new_pydict[\"context\"] = context_list\n",
    "    new_pydict_list.append(new_pydict)\n",
    "\n",
    "new_table_list = []\n",
    "for i in range(2):\n",
    "    new_table_list.append(pa.Table.from_pydict(new_pydict_list[i]))\n",
    "\n",
    "train_dataset = Dataset(new_table_list[0])\n",
    "valid_dataset = Dataset(new_table_list[1])\n",
    "train_datasets = DatasetDict({\"train\": train_dataset, \"validation\": valid_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets.save_to_disk(data_path + \"_new\")\n",
    "train_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question: remove -요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "     num_rows: 3952\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "     num_rows: 240\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'question'],\n",
       "     num_rows: 600\n",
       " })]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "data_path1 = \"/opt/ml/input/data/train_dataset\"\n",
    "dataset = load_from_disk(data_path1)\n",
    "org_datasets = []\n",
    "org_datasets.append(dataset[\"train\"])\n",
    "org_datasets.append(dataset[\"validation\"])\n",
    "\n",
    "data_path2 = \"/opt/ml/input/data/test_dataset\"\n",
    "dataset = load_from_disk(data_path2)\n",
    "org_datasets.append(dataset[\"validation\"])\n",
    "org_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(s):\n",
    "    s = str(s)\n",
    "    if s[-2] == \"요\":\n",
    "        s = s[:-2] + \"?\"\n",
    "    if s[-2] == \"나\":\n",
    "        s = s[:-2] + \"는가?\"\n",
    "    return s\n",
    "\n",
    "new_pydict_list = []\n",
    "for org_dataset in org_datasets:\n",
    "    new_pydict = org_dataset.to_dict()\n",
    "    question_list = [func(data) for data in new_pydict[\"question\"]]\n",
    "    new_pydict[\"question\"] = question_list\n",
    "    new_pydict_list.append(new_pydict)\n",
    "\n",
    "new_table_list = []\n",
    "for new_pydict in new_pydict_list:\n",
    "    new_table_list.append(pa.Table.from_pydict(new_pydict))\n",
    "\n",
    "train_dataset = Dataset(new_table_list[0])\n",
    "valid_dataset = Dataset(new_table_list[1])\n",
    "train_datasets = DatasetDict({\"train\": train_dataset, \"validation\": valid_dataset})\n",
    "\n",
    "test_dataset = DatasetDict({\"validation\": Dataset(new_table_list[2])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets.save_to_disk(data_path1 + \"_new\")\n",
    "test_dataset.save_to_disk(data_path2 + \"_new\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
